{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d664c768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tenacity import (  # for exponential backoff\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")\n",
    "import openai\n",
    "\n",
    "class OpenAIAPI:\n",
    "    def __init__(self, api_key,\n",
    "                 model=\"gpt-4-0613\",\n",
    "                 api_base=\"http://localhost:9581/v1\"\n",
    "                 ):\n",
    "\n",
    "        self.api_key = api_key\n",
    "        self.model = model\n",
    "        self.api_base = api_base\n",
    "\n",
    "    def chat_completion(self, messages, temperature=0.7, **kwargs):\n",
    "        return self.chat_completion_with_backoff(messages=messages,\n",
    "                                                 temperature=temperature,\n",
    "                                                 **kwargs)\n",
    "\n",
    "    @retry(wait=wait_random_exponential(min=1, max=10), stop=stop_after_attempt(50), reraise=False)\n",
    "    def chat_completion_with_backoff(self, messages, temperature, **kwargs):\n",
    "        if \"gpt\" in self.model:\n",
    "            if openai.__version__ > '1.0.0':\n",
    "                client = openai.AzureOpenAI(\n",
    "                    azure_endpoint=self.api_base,\n",
    "                    api_version=\"2023-07-01-preview\",\n",
    "                    api_key=self.api_key\n",
    "                )\n",
    "                return client.chat.completions.create(\n",
    "                    model=self.model,\n",
    "                    messages=messages,\n",
    "                    temperature=temperature,\n",
    "                    **kwargs\n",
    "                )\n",
    "            else:\n",
    "                openai.api_key = self.api_key\n",
    "                openai.api_base = self.api_base\n",
    "                openai.api_type = \"azure\"\n",
    "                openai.api_version = \"2023-07-01-preview\"\n",
    "                return openai.ChatCompletion.create(\n",
    "                    engine=self.model,\n",
    "                    messages=messages,\n",
    "                    temperature=temperature,\n",
    "                    **kwargs\n",
    "                )\n",
    "\n",
    "        else:\n",
    "            openai.api_key = 'none'\n",
    "            openai.api_base = self.api_base\n",
    "            return openai.ChatCompletion.create(\n",
    "                model=self.model,\n",
    "                messages=messages,\n",
    "                temperature=temperature,\n",
    "                **kwargs\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2173f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4 = OpenAIAPI(model=\"gpt-4-1106-preview\",\n",
    "                     api_key=\"O4ga4drYc3lOFnHYq6HDmQkvCFjWNgyW\",\n",
    "                     api_base=\"http://0.0.0.0:4400\",\n",
    "                     )\n",
    "\n",
    "response = gpt4.chat_completion(messages=[{\"role\": \"user\", \"content\": \"test\"}],\n",
    "                                    temperature=0.7)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06bb8467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Graph\n",
    "\n",
    "# Neo4j 数据库连接信息\n",
    "uri = \"bolt://localhost:7688\"\n",
    "username = \"neo4j\"\n",
    "password = \"20130806QAZ\"\n",
    "\n",
    "# 连接到数据库\n",
    "graph = Graph(uri, auth=(username, password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_script = \"\"\"\n",
    "MERGE (m:Movie {name:\"Top Gun\"})\n",
    "WITH m\n",
    "UNWIND [\"Tom Cruise\", \"Val Kilmer\", \"Anthony Edwards\", \"Meg Ryan\"] AS actor\n",
    "MERGE (a:Actor {name:actor})\n",
    "MERGE (a)-[:ACTED_IN]->(m)\n",
    "\"\"\"\n",
    "graph.run(init_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d15071",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_schema = \"\"\n",
    "results = graph.run(\"\"\"\n",
    "call db.schema.nodeTypeProperties\n",
    "\"\"\")\n",
    "for record in results:\n",
    "    db_schema += str(record) + \"\\n\"\n",
    "    \n",
    "results = graph.run(\"\"\"\n",
    "call db.schema.relTypeProperties\n",
    "\"\"\")\n",
    "for record in results:\n",
    "    db_schema += str(record) + \"\\n\"\n",
    "print(\"db_schema is: \", db_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f914c50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script generated:  MATCH (:Movie {name: \"Top Gun\"})<-[:ACTED_IN]-(a:Actor)\n",
      "RETURN count(a) as NumberOfActors \n",
      "\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "question = \"How many people played in Top Gun?\"\n",
    "\n",
    "response = gpt4.chat_completion(messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Generate Cypher script for the following question to query a neo4j database, and please reponse the script which I can directly run, without any other words or '```cypher'.\"},\n",
    "        {\"role\": \"system\", \"content\": \"The schema of Noe4j database is\" + db_schema},\n",
    "        {\"role\": \"system\", \"content\": \"Please use the schema above to generate your answer.\"},\n",
    "        {\"role\": \"user\", \"content\": question},\n",
    "    ], temperature=0.7)\n",
    "gpt_script = response.choices[0].message.content\n",
    "print(\"script generated: \", gpt_script, '\\n')\n",
    "\n",
    "results = graph.run(gpt_script)\n",
    "for record in results:\n",
    "    print(record)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be489fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "(No data)"
      ],
      "text/plain": [
       "(No data)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 清空所有数据\n",
    "graph.run(\"\"\"\n",
    "    MATCH (n)\n",
    "    DETACH DELETE n\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
